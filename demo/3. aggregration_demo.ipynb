{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a04454cc-57e7-491d-9379-0ff8893d0a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Demo of simple aggregration funcions in spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e0e8d66-28ad-4331-9b7d-a3c8f6f36651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/configurations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc8fb11-b8bf-411e-980f-cb04248648f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "race_results_df = spark.read.parquet(f\"{presentation_folder_path}/race_results\")\n",
    "display(race_results_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0190e8a3-8eee-48f8-833e-590c02af33f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, countDistinct, sum\n",
    "\n",
    "race_results_df.select(count(\"*\")).show()\n",
    "race_results_df.select(count(\"race_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "594f3b96-9c5c-43f8-8803-ea7c10d3b9b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# unique number of races\n",
    "race_results_df.filter(\"race_year = 2020\").select(countDistinct(\"race_name\")).show()\n",
    "\n",
    "race_results_df.select(countDistinct(\"race_year\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0698505-34d8-4070-be7d-a501ec343f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "574c7b22-2121-4bc0-a5f1-49bcc408a4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# total number of points hamiltion scored in 2020\n",
    "race_results_df.filter(\"race_year = 2020 and driver_name = 'Lewis Hamilton'\").select(sum(\"points\")).show()\n",
    "\n",
    "race_results_df.filter(\"race_year = 2020 and driver_name = 'Max Verstappen'\").select(sum(\"points\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91186a97-90ad-4b8c-9e7a-bab3b6eb5004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "race_results_df.filter(\"race_year = 2020 and driver_name = 'Lewis Hamilton'\").select(sum(\"points\"), countDistinct(\"race_name\")) \\\n",
    "    .withColumnRenamed(\"sum(points)\", \"total_points\") \\\n",
    "    .withColumnRenamed(\"count(DISTINCT race_name)\", \"number_of_races\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70634d96-2e5e-4568-80fe-61235278b7de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Using Group By method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f22a516-6538-4a47-99da-e63b170d8574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, avg\n",
    "# here we could only apply one aggregration function after group by because as soon as \n",
    "# a aggregration function is applied like sum the returned object becomes a DataFrame\n",
    "race_results_df.filter(\"race_year = 2019\") \\\n",
    "    .groupBy(\"driver_name\") \\\n",
    "    .sum(\"points\") \\\n",
    "    .orderBy(desc(\"sum(points)\")) \\\n",
    "    .withColumnRenamed(\"sum(points)\", 'total_points') \\\n",
    "    .limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b432e6c9-b9fb-4b8d-a2cd-0bcfd4da1699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to apply more than one aggregration after groupby we use .agg\n",
    "\n",
    "\n",
    "race_results_df.filter(\"race_year = 2020\") \\\n",
    "    .groupby(\"driver_name\") \\\n",
    "    .agg(sum(\"points\").alias(\"total_points\"), countDistinct(\"race_name\").alias(\"number_of_races\")) \\\n",
    "    .orderBy(desc(\"total_points\")) \\\n",
    "    .limit(10) \\\n",
    "    .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4777300-8be1-43c7-bd35-f770624149a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to apply more than one aggregration after groupby we use .agg\n",
    "\n",
    "\n",
    "race_results_df.filter(\"race_year = 2020\") \\\n",
    "    .groupby(\"team\") \\\n",
    "    .agg(sum(\"points\").alias(\"total_points\"), countDistinct(\"race_name\").alias(\"number_of_races\")) \\\n",
    "    .orderBy(desc(\"total_points\")) \\\n",
    "    .limit(10) \\\n",
    "    .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3048503-40e7-4deb-8d18-fa4b6babbc16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Windows Functions in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a274084c-6c63-4beb-b336-68729740f635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demo_groupby_df = race_results_df.filter(\"race_year in (2019, 2020)\") \\\n",
    "    .groupby(\"race_year\", \"driver_name\") \\\n",
    "    .agg(sum(\"points\").alias(\"total_points\"), countDistinct(\"race_name\").alias(\"number_of_races\")) \\\n",
    "    .orderBy(desc(\"total_points\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce7f340b-639f-4dbe-8b0e-2f28ef2a6a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, rank\n",
    "\n",
    "driverRankSpec = Window.partitionBy(\"race_year\").orderBy(desc(\"total_points\"))\n",
    "\n",
    "display(demo_groupby_df.withColumn(\"rank\", rank().over(driverRankSpec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdd92ad1-c799-43fe-8321-b224d695a5b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3. aggregration_demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
